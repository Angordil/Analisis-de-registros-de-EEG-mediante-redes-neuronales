{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross Validation: intento datos aleatorios simple conv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Angordil/Analisis-de-registros-de-EEG-mediante-redes-neuronales/blob/master/Cross_Validation_Conv2D.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "iOyVkn2J6CIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGUuh6U86VnO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qpjgdpx06c3a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWXINPyDC_hU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import utils\n",
        "from tensorflow.python.keras.models import Sequential, save_model, load_model\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.python.keras.applications import imagenet_utils\n",
        "from scipy.io import loadmat\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KAMXpJL86fQZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv(X_training, y_training1hot, X_validation, y_validation1hot):\n",
        "\n",
        "  num_classes = 6\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, (3,3), input_shape = (124,32,1)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    \n",
        "  history = model.fit(X_training, y_training1hot, epochs = 84, validation_data = (X_validation, y_validation1hot), shuffle = True, verbose = 1)\n",
        "\n",
        "  #model.save_weights('drive/TFG/Trial only with subject 1/Weights/weightsVoteModel'+str(subj_num+1)+'.hdf5')\n",
        "\n",
        "  return model, history\n",
        "\n",
        "def data_preparation(subj_num):\n",
        "  # Load data \n",
        "\n",
        "  subject = loadmat('drive/TFG/data/S'+str(subj_num+1)+'.mat')\n",
        "\n",
        "  # Inspect the EEG data for the first trial of the first subject:\n",
        "\n",
        "  X_training = subject['X_2D']\n",
        "  \n",
        "  N = 32\n",
        "  \n",
        "  electrodes = 124\n",
        "  \n",
        "  # ### Data Preparation\n",
        "\n",
        "  y_training = subject['categoryLabels'][0]\n",
        "\n",
        "  # Validation set will be defined when model.fit is done. It'll be a 10% of the training data\n",
        "\n",
        "  ## 1-Hot Encode Target Output Labels\n",
        "  num_classes = 6\n",
        "\n",
        "  y_training1hot = utils.to_categorical(y_training - 1 , num_classes)\n",
        "\n",
        "  print y_training1hot.shape\n",
        "\n",
        "  # Reshape training set\n",
        "\n",
        "  X_training = np.reshape(X_training,(-1, electrodes, N,1)) \n",
        "  \n",
        "  return X_training, y_training1hot, y_training\n",
        "\n",
        "def conf_matrix(y_validation, X_validation, model):\n",
        "  # ### Model Quality Check: Confusion Matrix\n",
        "  \n",
        "  y_validation_predictions = model.predict(X_validation, verbose = 1)\n",
        "\n",
        "  cnf_matrix = confusion_matrix(y_validation - 1, np.argmax(y_validation_predictions, axis = 1))\n",
        "\n",
        "  plt.figure()\n",
        "  class_names = ['Human Body', 'Human Face', 'Animal Body', 'Animal Face', 'Fruit Vegetable', 'Inanimate Object']\n",
        "  plot_confusion_matrix(cnf_matrix, classes = class_names, title = 'Confusion matrix ')\n",
        "  \n",
        "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting 'normalize = True'\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation = 45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "      cm = cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
        "      print('Normalized confusion matrix')\n",
        "    else:\n",
        "      print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max()/2.\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, cm[i, j], horizontalalignment = 'center', color = 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.ylabel('True label')\n",
        "      plt.xlabel('Predicted label')\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7mQGWMR7bhr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preparation and concatenation\n",
        "X_train, y_train1hot, y_train = data_preparation(0)\n",
        "\n",
        "for subj in range(1,10):\n",
        "  X_training, y_training1hot, y_training = data_preparation(subj)\n",
        "  X_train = np.append(X_train, X_training, axis = 0)\n",
        "  y_train1hot = np.append(y_train1hot, y_training1hot, axis = 0)\n",
        "  y_train = np.append(y_train, y_training, axis = 0)\n",
        "  print('Subj ' + str(subj) + ' added')\n",
        "\n",
        "random_index_training = np.random.randint(len(X_train), size = len(X_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJn2nbrqSqGY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Simple validation --> one loops, 10% as validation\n",
        "random_index_training = np.random.randint(len(X_train), size = len(X_train))\n",
        "start = 0 \n",
        "\n",
        "fin = start+5186\n",
        "if fin > len(X_train):\n",
        "  fin = len(X_train)\n",
        "  \n",
        "Xval = X_train[random_index_training[start:fin]]\n",
        "yval1hot = y_train1hot[random_index_training[start:fin]]\n",
        "yval = y_train[random_index_training[start:fin]]\n",
        "if start == 0:\n",
        "  Xtrain = X_train[random_index_training[fin:]]\n",
        "  ytrain1hot = y_train1hot[random_index_training[fin:]]\n",
        "else:\n",
        "  Xtrain = X_train[random_index_training[0:start]]\n",
        "  x = X_train[random_index_training[fin:]]\n",
        "  Xtrain = np.append(Xtrain, x, axis = 0)\n",
        "  \n",
        "  ytrain1hot = y_train1hot[random_index_training[0:start]]\n",
        "  y = y_train1hot[random_index_training[fin:]]\n",
        "  ytrain1hot = np.append(ytrain1hot, y, axis = 0)\n",
        "  \n",
        "model, history = conv(Xtrain, ytrain1hot, Xval, yval1hot)\n",
        "prediction = model.predict(Xval, verbose = 0)\n",
        "val = np.argmax(prediction, axis = 1) \n",
        "\n",
        "\n",
        "## Compare predicted classes with actual classes\n",
        "correct = 0\n",
        "for i in range(0, len(yval)):\n",
        "  if(yval[i]==(val[i]+1)):\n",
        "    correct = correct +1\n",
        "  else: correct = correct\n",
        "\n",
        "accuracy = correct*100/len(yval)\n",
        "print (str(accuracy) + ' % - loop ' )\n",
        "\n",
        "start = fin\n",
        "\n",
        "conf_matrix(yval, Xval, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KfGAi7fSTKQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Accuracy over time')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc = 'upper left')\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cN40iTeNTNP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Cross Entropy Loss over Time')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc = 'upper left')\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ywsdLErJoT6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cross validation --> ten loops, 10% as validation\n",
        "random_index_training = np.random.randint(len(X_train), size = len(X_train))\n",
        "start = 0 \n",
        "\n",
        "for loop in range(0,10):\n",
        "  fin = start+5186\n",
        "  if fin > len(X_train):\n",
        "    fin = len(X_train)\n",
        "    \n",
        "  Xval = X_train[random_index_training[start:fin]]\n",
        "  yval1hot = y_train1hot[random_index_training[start:fin]]\n",
        "  yval = y_train[random_index_training[start:fin]]\n",
        "  if start == 0:\n",
        "    Xtrain = X_train[random_index_training[fin:]]\n",
        "    ytrain1hot = y_train1hot[random_index_training[fin:]]\n",
        "  else:\n",
        "    Xtrain = X_train[random_index_training[0:start]]\n",
        "    x = X_train[random_index_training[fin:]]\n",
        "    Xtrain = np.append(Xtrain, x, axis = 0)\n",
        "    \n",
        "    ytrain1hot = y_train1hot[random_index_training[0:start]]\n",
        "    y = y_train1hot[random_index_training[fin:]]\n",
        "    ytrain1hot = np.append(ytrain1hot, y, axis = 0)\n",
        "    \n",
        "  model, history = conv(Xtrain, ytrain1hot, Xval, yval1hot)\n",
        "  prediction = model.predict(Xval, verbose = 0)\n",
        "  val = np.argmax(prediction, axis = 1) \n",
        "\n",
        "  \n",
        "  ## Compare predicted classes with actual classes\n",
        "  correct = 0\n",
        "  for i in range(0, len(yval)):\n",
        "    if(yval[i]==(val[i]+1)):\n",
        "      correct = correct +1\n",
        "    else: correct = correct\n",
        "\n",
        "  accuracy = correct*100/len(yval)\n",
        "  print (str(accuracy) + ' % - loop ' + str(loop+1))\n",
        "  if loop == 0:\n",
        "    Acc = [accuracy]\n",
        "    hist = [history]\n",
        "  else:\n",
        "    Acc = np.append(Acc, [accuracy], axis = 0)\n",
        "    hist = np.append(hist, [history], axis = 0)\n",
        "    \n",
        "  start = fin\n",
        "  \n",
        "  conf_matrix(yval, Xval, model)\n",
        "  \n",
        "print(\"Final accuracy: \" + str(Acc) + \"%\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}